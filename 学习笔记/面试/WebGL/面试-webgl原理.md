# WEBGL原理

## 1.什么是WEBGL

WEBGL是一种3D绘图标准，他是从OpenGL的一个特殊版本OpenGLES中派生出来的，也就是说WEBGL是基于OpenGL ES 2.0的一种衍生技术，他将JavaScript 和 OpenGL ES 2.0 结合在一起，通过增加 OpenGL ES 2.0 的 一个 JavaScript 绑定，WebGL 可以为 HTML5 Canvas 提供硬件 3D 加速渲染，这样 Web 开发人员就可以借助系统显卡来在浏览器里更流畅地展示 3D 场景和模型了

## 2.WEBGL渲染管线

渲染管线其实就是图形的渲染过程，他主要有两个功能

一是将物体的3D坐标转换到屏幕空间2D坐标，二就是为每个像素点进行着色

流程主要有

+   顶点处理：顶点处理一般来说是对顶点缓冲区的各个输入顶点的数据进行一些矩阵变换(模型矩阵、视图矩阵、投影矩阵)将3D对象的局部坐标系转换为裁剪空间下的坐标系，该阶段是可以编程的，采用glsl语言进行编写
+   图元装配：在顶点处理完毕之后，就需要将顶点组合为一个个图元，绘制函数drawArrays()或drawElements()第一个参数绘制模式mode控制顶点如何装配为图元。图元装配阶段会进行裁剪和背面剔除等相关优化，目的是减少进入光栅化的图元的数量，加速渲染过程
    +   裁剪：在图元组装完毕之后，会将完全位于视锥体(通过顶点着色器的投影变换之后是一个立方体，更有利于我们操作)之外的顶点裁剪掉，同时对部分位于视锥体之外的图元会进行裁剪操作，会在可见与不可见的交界处产生新的顶点(裁剪阶段使用4分量的齐次坐标)。我们可以将裁剪操作推迟到屏幕坐标中进行，使用一种叫做裁切(Scissoring)的技术在帧缓存中执行裁剪操作，对于几何实体一般在帧缓存之前进行裁剪更好一些，帧缓存中的裁剪一般只适合于光栅对象，比如像素块。
    +   背面剔除：通常情况下，三角形的3个顶点是逆时针顺序进行排列时，我们会认为是正面，而顺时针排序时，我们会认为是背面。使用利用顶点计算得到的矩阵的行列式去确定三角形到底是正面还是背面，这是一种避免渲染背对观察者的几何体面来提高性能的优化措施
+   光栅化：在光栅化之前会进行屏幕映射(透视除法以及视口变换),都由硬件实现，光栅化是个离散化的过程，将3D连续的物体图元转化为片元的过程。光栅化就是将图元转换为片元。片元是一个像素大小的基本单位，但是它并非像素，而是像素的前身。片元相比于像素，除了 RGBA 之外，这些片元还具有三维空间位置数据，如深度值，法线，纹理坐标等信息。 片元的位置数据来自几何体的顶点插值计算，插值过程是光栅单元自动完成的
    +   透视除法：由硬件执行透视除法后变换到标准设备空间(也叫标准视体(CVV)其对应的坐标系叫归一化设备坐标(NDC))
    +   视口变换：通过视口变换将NDC坐标变换到屏幕坐标。
+   片元处理，对于片元处理还可以细分：裁剪测试、多重采样片段、归属测试、模板测试、深度测试、alpha测试、alpha融合、抖动
    +   裁剪测试：严格一点应该叫裁切测试，他与图元装配阶段的裁剪不一样，图元阶段的裁剪是不可配置的，而裁切测试是一个可配置阶段，他会将限定区域之外的片元舍弃掉，以减少帧缓冲的绘制缓存。通过`gl.enable(gl.SCISSOR_TEST)`启用裁剪测试.通过` gl.scissor(0,100, 350, 300)`设置裁剪区域。通过`  gl.disable(gl.SCISSOR_TEST)`禁用裁剪测试
    +   归属测试：用于判断像素是否为当前上下文所有，当前上下文只显示当前上下文的数据
    +   模板测试：模板测试默认不开启，可以理解为一个mask，通过这个mask的值来确定那些片段被丢弃和保留，通过`glEnable(GL_STENCIL_TEST)`来开启
    +   深度测试：比较当前片段的深度值是否比深度缓冲中预设的值小(默认比较方式)，如果是更新深度缓冲和颜色缓冲；否则丢弃片段不更新缓冲区的值。
    +   多重采样片段：一个抗锯齿的算法，取多个采样点去计算覆盖率以此来得到该处片元的颜色值
    +   alpha测试：将一个像素点的alpha值和一个固定值比较，如果比较的结果失败，像素将不会被写到显示输出中，当片元透明度大于等于这个阈值的时候，就会按照普通不透明的物体处理方式来处理，进行深度测试，深度写入等。透明度测试无法得到真正的半透明效果。
    +   alpha融合(混合):引入Alpha技术是为了实现半透明的效果。将新的颜色值和已经存在的颜色值进行组合，得出融合后的颜色值
    +   抖动：解决可使用的颜色过少会出现色带的问题，通过较少的颜色来模拟较多颜色的技术


## 3.顶点着色器的常用属性类型

+   attribute变量：用户自定义变量，一般是存储顶点属性的变量；

+   uniform变量：恒值变量，一般表示每个顶点都一致的变量，比如变换矩阵、光照等；

-   varying变量：易变变量，将顶点着色器的数据传递给片元着色器时使用；
-   内置常量：WebGL 内部的常量；

## 4.对于顶点处理中的矩阵变换理解

+   模型矩阵，**局部空间转化到世界空间**
+   视图矩阵，相机变换的逆变换，**世界空间转换到观察空间**。
+   模型视图矩阵，`modelViewMatrix `= `viewMatrix `* `modelMatrix`
+   透视矩阵,**观察空间转换到裁剪空间**
+   模型视图透视矩阵，`modelViewPersectiveMatrix`=`persectiveMatrix` * `viewMatrix` * `modelMatrix`
+   后续裁剪空间会经`透视除法`变换到标准设备空间
+   标准设备空间会经`视口变换`变换到屏幕空间(使用glViewport()可以进行视口变换)

## 5.对于离屏渲染的理解-[使用FBO实现离屏渲染](https://blog.csdn.net/srk19960903/article/details/77898447)

程序中执行方法createFramebuffer()，会描述为创建一个帧缓冲区对象， 其实就是在显存上开辟一个区域作为帧缓冲区，有独显的帧缓冲区就在显卡上，没有独显的创建帧缓冲区就位于主存上。createFranebuffer()创建的自定义帧缓冲区，自定义帧缓冲区的颜色缓冲区的数据不会被视频控制读取显示在canvas画布上，所以称为离屏缓存也叫离屏渲染

离屏渲染一般的应用就是将需要离屏渲染的物体绘制到帧缓冲当中并将其当成一个纹理，然后对这个纹理进行二次处理，处理完成之后再将这个纹理贴到需要渲染的物体上

整体实现思路就是：

1.创建FBO对象(FrameBufferObject)，也就是帧缓冲对象，FBO在使用时必须对其进行绑定，如果绑定参数为NULL则说明绑定系统默认帧缓冲，即直接绘制到屏幕上。

2.如果需要储存一些深度或模板信息，则还需要创建一个渲染缓存对象(RenderBufferObject)

3.创建纹理对象，将绘制完成的帧缓冲对象以纹理的形式存放(调用framebufferTexture2D)，以供下次使用。

4.进行两次绘制，在第一次绘制时绑定帧缓冲区对象，这样绘制就会在绑定帧缓冲区中进行绘制，在绘制完记得解除绑定，在第二次绘制因为解除了帧缓冲区对象的绑定，所以会在默认帧缓冲区进行绘制，即直接绘制到屏幕上，由于我们纹理保存着第一次绘制的结果，所以可以直接将第一次绘制的结果作为纹理作用在第二次绘制的结果上。这样就完成了离屏渲染

## 6.对于透视除法的理解

执行透视除法是为了实现透射投影中近大远小的视觉效果，经过了投影矩阵Projection的变换后，W分量保留了观察空间中物体Z坐标的信息，所以透视除法才能够根据距离摄像机的远近正确实现透视效果。

透射除法是由硬件自动执行的，也就是说透视除法在正交投影和透视投影中都会被执行，只不过正交投影变换并没有改变W分量的值(W分量的值仍是1)，所以透视除法并没有实际的效果。

我们从这里也明白了使用齐次坐标的意义，其实就是为了正确记录下投影变换前(观察空间)中物体的深度信息，也就是Z坐标的值。

## 7.对于拾取(Picking)的理解

与投影变换和视口变换相反的一种变换是：拾取(Picking)。也就是根据屏幕坐标反算出对 应的3D对象。我们需要做逆于投影视口变换的操作，将屏幕坐标变换到3D坐标。拾取变换的过程如下所示： 

+   通过视口变换矩阵逆矩阵将屏幕坐标变换到NDC坐标 
+   然后通过乘以W分量(投射除法的逆变换)将NDC坐标变换到裁剪坐标 
+   通过投影矩阵逆矩阵将裁剪坐标变换到观察坐标 
+   求出经过原点O以及点的拾取射线 
+   拾取射线位于观察空间，通过将拾取射线变换到局部空间进行相交行检测 (这里将拾取 变换到局部空间是为了减少运算量，将物体的每个图元变换到世界坐标效率较低)

## 8.对曲面细分的理解

曲面细分是一种三角面细分技术，在渲染管线中是一个可选阶段。借助曲面细分的技术实现细节层次(Level-ofDetail)的机制，使得离摄像机越近的物体具有更加丰富的细节，而远离摄像机的物体具有较少的细节。

## 9.对视锥体的理解

视锥体一般通过上下左右远近六个平面来定义，一般通过投影矩阵将物体从观察空概念变换到裁剪空间，裁剪空间是一个以原点为中点的立方体，这个立方体可以看作一个视锥体，当图元位于边界之外就会被剔除，不同的投影矩阵对应的视锥体不一样，常见的投影矩阵有透视投影和正交投影，透视投影对应的视锥体是一个梯形，远大近小，而正交投影对应的是一个正方体/长方体,一般通过近平面、远平面、垂直视场角、屏幕纵横比四个参数来定义视锥体。

## 10.对于z-Fighting的理解

Z-fighting是由于深度缓冲精度不够带来的问题。当同一个位置的片段具有相似的深度值 时，由于深度缓冲精度不够无法决定应该显示那个片段，导致片段之间抢占深度的至高点，造成了视觉上的假象， 透视除法后的z分量具有了非线性的关系，近平面处有较 好的深度精度，而靠近远平面处深度精度较低。解决z-fighting的一个常见技巧是让物体之间有一些偏移，不要将物体靠的太近；另一种技 巧是使用高精度的深度缓冲。比如使用32bits的深度缓冲，然而这样会占用更多的显存资源。

## 11.对深度写入和深度测试的理解

深度测试其实就是一种比较算法，比较当前片段的深度值是否比深度缓冲中预设的值小(默认比较方式)，如果是更新深度缓冲和颜色缓冲；否则丢弃片段不更新缓冲区的值。

深度写入可以理解为更新深度缓冲，而深度测试可以理解为确定是否遮挡，

## 12.对alpha融合的理解

引入Alpha技术是为了实现半透明的效果，特别的：当场景中既有不透明物体，又有半透明物体时，我们需要先渲染不透明物体，渲染顺序为从前往后；然后再渲染半透明物体，渲染顺序为从后往前。我们需要对不透明和半透明物体分开渲染是因为：我们可以透过半透明物体看到半透明物体背后的东西，所以对半透明物体进行渲染时需要后面图层的信息，才能够正确进行混合。对不透明物体按从近到远进行渲染是为了减少深度颜色缓冲器的写入操作，提升性能；而半透明物体需要遵循画家算法由远及近进行渲染是为了渲染的正确性。

## 13.对隐藏面消除的理解(HSR)

隐藏面消除也叫作可见面确定。图元组装的裁剪(Clipping)、背面剔除和Z-Buffer技术其实就是隐藏面消除的一种，只不过剔 除的粒度有所不同，其中裁剪操作针对的是图元，而Z-Buffer是针对像素点。不同的隐藏 面消除技术的主要区别在于剔除的粒度以及不同的剔除目的，但是最终目的都是相同的： 减少到达片段着色器的片段的数量，提高渲染的性能。

较常见的HSR技术：

+   视椎体剔除：对于大场景我们根本不可能每帧对每个物体都进行 渲染，人们发现我们其实只需要渲染那些摄像机看得到的物体，也就是位于视椎体内的物 体，其他位于视椎体外的物体根本不需要渲染，我们可以将其进行剔除，不送入渲染管线，提升我们的渲染效率。

+   入口剔除 :当我们位于室内时，我们就可以使用入口剔除技术进行裁剪优化了。我们可以将室内的门 或者窗户看做视椎体来进行裁剪。不过我们其实看到入口剔除有很大的局限性，一般只能 在室内环境下使用，无法再室外场景使用该技术，对于室外的大场景我们一般需要使用下 面介绍的遮挡剔除技术。
+   遮挡剔除：遮挡剔除的实现方法有很多，既有基于CPU的，也有基于GPU的，也可 以混合使用CPU和GPU进行处理。一般进行遮挡剔除时，我们需要通过离线烘焙的方法来 预先计算出潜在可视集合(Potentially Visible Set，PVS)。PVS记录了每个地形块(Tiles)可 能看到的物体的集合，用于运行时查找计算。在计算PVS时我们会将场景划分为小的地形 块，在每个块上随机选取N个采样点，以这些采样点为起点发出射线来获取场景中相交的 物体，记录下物体的ID，求出每个块对应的ID的集合。在运行时根据摄像机的位置获取每 个块可见的物体进行渲染。

## 14.锯齿产生的原因

锯齿是由于采样不足造成的，由于我们的像素点都是离散的，而当我们使用离散的像素点来表示一个连续的物体的时候，就会丢失一部分物体的信息，导致锯齿的产生，抗锯齿技术就是为了减缓这种影响，例如超级采样抗锯齿(SSAA)他的主要原理就是将低分辨率的物体拿到更高分辨率的屏幕去渲染，在把高分辨率渲染的缓冲区的结果采样到原分辨率上，这样就可以得到更好的效果，但是也有一定确定，SSAA的计算量是非常大的，光栅化和片元着色器都是原来的数倍，渲染缓存大小也是原来的数倍，还比如多重采样抗锯齿(MSAA)。在MSAA中我们会使用多个采样点来决定覆盖率的问题(Coverage)。MSAA的原理其实和SSAA差不多，不过在光栅化阶段计算三角面是否覆 盖了片段的每个采样点，得到采样点**覆盖率**的数值，接下来在片段着色器计算这个片段的颜色值(只计算一次)，然后最终的颜色会乘上这个覆盖率。

## 15.什么是顶点着色器，什么是片元着色器

顶点着色器一般用于处理由attribute修饰符所定义的属性所携带的顶点相关的操作，比如矩阵变换(例如模型变换，视图变换，投影变换)，生成纹理坐标、计算光照等相关操作

片岩着色器一般用于处理由光栅化阶段得到的片元，对每一个片元进行相关操作填充颜色，比如可以对纹理取样，然后作用于片元上，还可以通过uv去改变一些片元实际的表现效果。

## 16.为什么引入齐次坐标

从计算的角度, 统一计算，把各种变换都统一了起来，即 把缩放，旋转，平移等变换都统一起来，都表示成一连串的矩阵相乘的形式。保证了形式上的线性一致性

还可以解决无穷远点无法表示的问题

正确记录下投影变换前(观察空间)中物体的深度信息，也就是Z坐标的值
